<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <title>Reporte Primer Parcial - Procesamiento de Im√°genes</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <header>
    <h1>üìã Reporte Primer Parcial</h1>
    <h2>Procesamiento de Im√°genes</h2>
    <p>Equipo: Panteras Verdes xD</p>
    
  <!-- Apartado desplegable -->
  <details>
    <summary><b>Integrantes</b></summary>
    <ul>
      <li>Gonz√°lez Garc√≠a Hannah Andrea -ID:0276927</li>
      <li>Reza Zatarain Jes√∫s Miguel </li>
      <li>Guti√©rrez Castellanos Carol Kristel</li>
    </ul>
  </details>
</header>
  <nav>
    <ul>
      <li><a href="#intro">1. Introducci√≥n</a></li>
      <li><a href="#fundamentos">2. Fundamentos de la Informaci√≥n Visual</a></li>
      <li><a href="#procesamiento">3. Procesamiento de Im√°genes</a></li>
      <li><a href="#abstract">4. Abstract (English)</a></li>
      <li><a href="#conclusiones">5. Conclusiones</a></li>
    </ul>
  </nav>

  <main>
    <!-- INTRODUCCI√ìN -->
    <section id="intro">
      <h2>1. Introducci√≥n</h2>

<details>
  <summary><h3>1.0.1 Herramientas y fundamentos en Python</h3></summary>
<p>
En las primeras semanas del curso nos involucramos y trabajamos en <b>Jupyter Notebooks</b>, un entorno que permite
combinar c√≥digo, texto y visualizaciones, ideal para documentar experimentos en procesamiento digital de im√°genes.
Asi mismo revisamos las <b>instrucciones b√°sicas de Python</b> (uso de <code>print()</code>, declaraci√≥n de variables,
tipos de datos primitivos como <i>int, float, str, bool</i>) y estructuras como listas y tuplas.
Tambi√©n se abord√≥ la <b>conversi√≥n de tipos</b> (casting), fundamental para transformar datos num√©ricos
que m√°s adelante representar√°n valores de p√≠xeles en im√°genes.
</p>

<h3>Listas, Indexing y Slicing</h3>
<p>
Repaso de <b>listas</b>.<br>
  <li>      Declaraci√≥n: <code>lista = [1,2,3,4,5,6,7]</code></li>
  <li>      Contar elementos de una lista: <code>len(lista)</code></li><br>
<i><b>Indexaci√≥n positiva</b></i>: Sirve para acceder a elementos invideduales.
<i><br><b>Indexaci√≥n negativa<</b></i>: para acceder a elementos de una secuencia (como listas, tuplas o cadenas) desde el final, en vez del principio.
<i>slicing</i>: para extraer subconjuntos. Estas operaciones son clave porque en im√°genes, los datos suelen organizarse en colecciones y matrices.
<i>Ejemplo: <code>lista[0:3]</code>devuelve los primeros tres elementos).</i></p> 

<pre><code class="language-python">
# Lista de ejemplo
numeros = [10, 20, 30, 40, 50]

print(numeros[0])    # Primer elemento ‚Üí 10
print(numeros[-1])   # √öltimo elemento ‚Üí 50
print(numeros[1:4])  # Slicing: [20, 30, 40]
</code></pre>

<p>
Adem√°s, se reforz√≥ el uso de bucles <code>for</code> para recorrer listas, cadenas o secuencias generadas con <code>range()</code>.
Estas estructuras de control son la base para recorrer arreglos de p√≠xeles y aplicar transformaciones sistem√°ticas.
</p>

<h3> Introducci√≥n a NumPy</h3>
<p>
El paso m√°s importante fue la introducci√≥n a <b>NumPy</b>, la librer√≠a cient√≠fica que permite trabajar con
arreglos multidimensionales. A diferencia de las listas nativas, los arreglos NumPy son m√°s r√°pidos,
consumen menos memoria y permiten operaciones vectorizadas, lo cual es esencial al manejar im√°genes.
</p>

<pre><code class="language-python">
import numpy as np

# Crear un arreglo NumPy
matriz = np.array([[1, 2, 3],
                   [4, 5, 6],
                   [7, 8, 9]])

print(matriz.shape)  # (3, 3) ‚Üí 3 filas, 3 columnas
print(matriz.dtype)  # int64 ‚Üí tipo de datos
print(matriz[1, 2])  # Acceder a la fila 2, columna 3 ‚Üí 6
</code></pre>
<p>
En resumen: <br>
  ‚Ä¢	shape ‚Üí devuelve la dimensi√≥n del arreglo (ej. filas y columnas en una matriz).<br>
	‚Ä¢	dtype ‚Üí indica el tipo de dato que contienen los elementos (muy √∫til para im√°genes en escala de grises o color).<br>
	‚Ä¢	size ‚Üí n√∫mero total de elementos en el arreglo..
</p>
<p>
Con NumPy se establecen las bases para representar im√°genes como <b>matrices multidimensionales</b>,
donde cada elemento corresponde a un p√≠xel. Este conocimiento ser√° esencial en los siguientes m√≥dulos,
al aplicar filtros, transformaciones y an√°lisis sobre datos visuales.
</p>
</details>

<details>
  <summary><h3>1.1. Definici√≥n de visi√≥n humana</h3></summary>
      <h4>1.1.1. Estructura del ojo humano</h4>
      <p>El ojo humano est√° compuesto por <b>neuronas y fotorreceptores</b>, responsables de captar est√≠mulos luminosos y convertirlos en se√±ales el√©ctricas.
Entre ellos se distinguen los <b>conos</b>, que permiten percibir detalles finos y colores (rojo, verde y azul), funcionando de manera √≥ptima en presencia de luz; y los <b>bastones</b>, que se concentran en detectar formas generales y escalas de grises, siendo m√°s sensibles en condiciones de baja iluminaci√≥n.
</p>

<p>
En conjunto, estas estructuras conforman la base del sistema visual y resultan esenciales para comprender la transici√≥n hacia los <b>sensores digitales</b> en las c√°maras modernas.
</p>

<!-- Imagen ojo humano -->
<img src="assets/ojo1.png" alt="Estructura del ojo humano" width="400">



      <h4>1.1.2. Sistema de visi√≥n humana</h4>
<p>
El sistema visual integra estructuras como el <b>nervio √≥ptico</b>, el <b>hipot√°lamo</b> y la <b>corteza visual</b>, encargadas de procesar la informaci√≥n captada por el ojo y traducirla en percepci√≥n consciente.
</p>

<h5>Visi√≥n humana: Fun Facts</h5>
<ul>
  <li>El 70% de nuestros receptores sensoriales se emplean en la visi√≥n.</li>
  <li>La vista es considerada nuestro sentido dominante.</li>
  <li>Nuestra resoluci√≥n visual se aproxima a <b>576 megap√≠xeles</b>.</li>
</ul>

<h5>Las ondas</h5>
<p>
La <b>luz</b> es radiaci√≥n electromagn√©tica que viaja en ondas, caracterizadas por su <i>frecuencia</i> y <i>amplitud</i>.
En la luz, la frecuencia est√° asociada al <b>color</b> (tonalidad) y la amplitud al <b>brillo</b>.
Por ejemplo, los colores azul y violeta poseen alta frecuencia, mientras que el rojo corresponde a frecuencias bajas.
</p>

<p>
En el caso del <b>sonido</b>, la frecuencia determina el tono y la amplitud se percibe como volumen. Aunque distintos en naturaleza, ambos comparten principios ondulatorios.
</p>

<!-- Imagen ondas -->
<img src="assets/ondas.png" alt="Frecuencia y amplitud en ondas" width="500">
</details>   

      <h3>1.2. Definici√≥n de visi√≥n computacional</h3>   
<p>
La c√°mara digital emula el funcionamiento del ojo humano mediante sensores capaces de transformar la luz en se√±ales el√©ctricas.
Existen principalmente dos tipos de sensores:
</p>
<ul>
  <li><b>CMOS</b> (Complementary Metal-Oxide Semiconductor)</li>
  <li><b>CCD</b> (Charge-Coupled Device)</li>
</ul>
<p>
Ambos cumplen la misma funci√≥n: realizar la <b>conversi√≥n anal√≥gica-digital (A/D)</b> de la informaci√≥n lum√≠nica.
</p>

<!-- Imagen sensores -->
<img src="assets/sensor1.png" alt="Tipos de sensores" width="400">
<img src="assets/sensor2.png" alt="Conversi√≥n A/D en c√°mara digital" width="400">

<h4>Filtro de Bayer</h4>
<p>
El <b>filtro de Bayer</b> es un patr√≥n de colores que se coloca sobre el sensor de la c√°mara para registrar la informaci√≥n de color en tres canales: rojo, verde y azul (RGB). 
Este proceso imita la forma en que los conos del ojo humano perciben la luz y permite reconstruir im√°genes digitales a todo color.
</p>


<h3>1.7. Etapas fundamentales del DIP</h3>

<h4>1.7.1. Visi√≥n de bajo nivel</h4>
<p>
La visi√≥n de bajo nivel son a las operaciones iniciales que se realizan directamente sobre los p√≠xeles de una imagen. 
Como: <b>mejora del contraste</b>, <b>reducci√≥n de ruido</b>, <b>filtrado</b> y <b>detecci√≥n de bordes</b>. 
Su objetivo principal es mejorar la calidad visual de la imagen sin interpretar a√∫n el contenido.
</p>

<h4>1.7.2. Visi√≥n de alto nivel</h4>
<p>
La visi√≥n de alto nivel se centra en la <b>interpretaci√≥n sem√°ntica</b> de las im√°genes. 
La computadora no solo procesa p√≠xeles, sino que intenta <b>reconocer patrones, objetos o escenas</b>. 
Ejemplos incluyen el <b>reconocimiento facial</b>, la <b>clasificaci√≥n de im√°genes</b> o la <b>detecci√≥n de movimiento</b>. 
En esta etapa, los algoritmos buscan comprender "qu√©" hay en la imagen y darle un significado.
</p>

    </section>

    <!-- FUNDAMENTOS -->
    <section id="fundamentos">
      <h2>2. Fundamentos de la Informaci√≥n Visual</h2>

      <h3>2.1. Adquisici√≥n de im√°genes</h3>
      <p><h4>Caracterizaci√≥n Matematica: </h4></p>
		<p>Definici√≥n: Una imagen puede ser definida como una funci√≥n de dos dimenciones <code>f(x,y)</code> donde las variables son las cordenadas espaciales (plano) y f es la intensidad o el nivel de gris de la imagen en dicha cordenada.
		Cuando las cantidades de la funci√≥n y sus variables son  discretas y finitas. A dicha imagen se le llama: <i>Imgen digital</i></p>
		<p>Ejemplo 1: La siguiente imagen en <b>escala de grises</b> es una muestra de la representaci√≥n de un ada d√≠gito puede ser representado por un arreglo. 
		<ul>
			<li>Lo negro que puede llegar a ser un pixel esta representado con valores entre 0 y 1</li>
			<li>Es normal que las imagenes tengan valores entre 0 y 255 ya que tiene que ver por el hecho de que las computadoras almacenan n√∫meros de 8 bits</li>

		<!---IMagen del 1 en matriz--->
		</ul></p>
		<p>Ejemplo 2:
		<ul>
			<li>Las imagenes a color se pueden representar con una combinacion de Rojo (R), Verde(G) y Azul(B)</li>
			<li>Un arreglo de una imagen a color tiene 3 dimensiones: Alto, ancho y canales de color(3)</li>
			<li>Cada canal necesita un color, ya que la omputadora solo sabe que hay 3 canales de intensidad</li>

		<!---IMagen del 2 en matriz--->
		</ul></p>

      <h3>2.2. Digitalizaci√≥n de im√°genes</h3>
      <p>[Descripci√≥n]</p>

      <h4>2.2.1. Tipos y formatos de archivos de im√°genes digitales</h4>
      <ul>
        <li>[Formato 1]</li>
        <li>[Formato 2]</li>
      </ul>
    </section>

    <!-- PROCESAMIENTO -->
    <section id="procesamiento">
      <h2>3. Procesamiento de Im√°genes</h2>

      <h3>3.1. Operaciones entre p√≠xeles</h3>
      <h4>3.1.1. Vecinos de un p√≠xel</h4>
      <p>En el <strong>procesamiento de im√°genes</strong>, los vecinos de un p√≠xel se refieren 
    a los p√≠xeles que rodean a uno central en una posici√≥n <em>(x, y)</em>, 
    definidos mediante una ventana. Estos vecinos se clasifican en:
  </p>

  <h3>4-vecinos</h3>
  <p>
    Son los p√≠xeles ubicados arriba, abajo, izquierda y derecha del p√≠xel central:
  </p>
  <ul>
    <li>(x - 1, y)</li>
    <li>(x + 1, y)</li>
    <li>(x, y - 1)</li>
    <li>(x, y + 1)</li>
  </ul>

  <h3> 8-vecinos</h3>
  <p>
    Incluyen los 4-vecinos y adem√°s los p√≠xeles en las diagonales:
  </p>
  <ul>
    <li>(x - 1, y - 1)</li>
    <li>(x - 1, y + 1)</li>
    <li>(x + 1, y - 1)</li>
    <li>(x + 1, y + 1)</li>
  </ul>

  <p>
    Estas vecindades son esenciales para operaciones como 
    <em>filtrado</em>, <em>detecci√≥n de bordes</em> o 
    <em>morfolog√≠a matem√°tica</em>, donde el valor de cada p√≠xel 
    se modifica en funci√≥n de sus vecinos.
	  
	  
	  </p>

      <h4>3.1.2. Adyacencia y conectividad</h4>
      <p>Dos p√≠xeles pueden considerarse <strong>"vecinos"</strong> entre s√≠ basados en:
  </p>
  <ul>
    <li>Su cercan√≠a espacial (las posiciones).</li>
    <li>La similitud entre sus valores (intensidad o color).</li>
  </ul>

  <h3>Tipos m√°s comunes de Adyacencia</h3>

  <h4>Adyacencia 4</h4>
  <p>
    Dos p√≠xeles son adyacentes si comparten un lado vertical u horizontal.
  </p>
  <p><em>Ejemplo:</em> el p√≠xel (x, y) es adyacente a (x + 1, y) o (x, y + 1).</p>

  <h4>Adyacencia 8</h4>
  <p>
    Incluye lados y esquinas diagonales.
  </p>
  <p><em>Ejemplo:</em> el p√≠xel (x, y) es adyacente a (x + 1, y + 1).</p>

  <h4>Adyacencia Mixta</h4>
  <p>
    Es un tipo de adyacencia usado en im√°genes binarias, donde se combinan
    reglas de adyacencia 4 y 8 dependiendo de la aplicaci√≥n.
  </p>

  <h3>Conectividad</h3>
  <p>
    La conectividad se refiere a c√≥mo se relacionan los p√≠xeles en una imagen. 
    Dos p√≠xeles se consideran conectados si existe un camino entre ellos a trav√©s 
    de otros p√≠xeles adyacentes, siempre que esos p√≠xeles tengan valores similares.
  </p>
  <p>
    Esto significa que, si tienes una serie de p√≠xeles del mismo color o muy parecidos, 
    puedes conectar esos p√≠xeles entre s√≠. La conectividad ayuda a definir regiones 
    o caminos en la imagen bas√°ndose en la proximidad y la similitud de los colores.
  </p>

  <h4>Tipos de Conectividad</h4>
  <ul>
    <li><strong>Conectividad 4:</strong> la ruta solo puede usar movimientos horizontales o verticales.</li>
    <li><strong>Conectividad 8:</strong> permite movimientos diagonales adem√°s de horizontales y verticales.</li>
  </ul>

      <h3>3.2. Transformaciones de Intensidad y Filtrado Espacial</h3>

      <h4>3.2.1. Funciones B√°sicas</h4>
      <ul>
        <li>3.2.1.1. Negativos</li>
		  <p>
    Las transformaciones de intensidad modifican el valor de cada p√≠xel de forma 
    independiente para mejorar la apariencia de una imagen. 
    Una de estas es la <strong>transformaci√≥n negativa</strong>.
  </p>

  <h3>Transformaci√≥n Negativa</h3>
  <p>
    Esta transformaci√≥n invierte los niveles de brillo de la imagen original: 
    los p√≠xeles claros se vuelven oscuros y los p√≠xeles oscuros se vuelven claros.
  </p>

  <p><strong>F√≥rmula matem√°tica:</strong></p>
  <pre>
    s = L - 1 - r
  </pre>

  <p>
    Donde:
  </p>
  <ul>
    <li><strong>s</strong>: nuevo valor del p√≠xel.</li>
    <li><strong>r</strong>: valor original del p√≠xel.</li>
    <li><strong>L</strong>: n√∫mero total de niveles de intensidad.</li>
  </ul>

  <h3>Ejemplo</h3>
  <p>
    En una imagen de 8 bits con 256 niveles de gris, 
    un p√≠xel con un valor de <strong>10</strong> (casi negro) 
    se transforma en un p√≠xel con un valor de <strong>245</strong> (casi blanco).
  </p>

  <p>
    La transformaci√≥n negativa es √∫til para realzar detalles ocultos 
    en √°reas muy oscuras de una imagen, haci√©ndolos m√°s visibles al convertirlos en tonos m√°s claros.
  </p>

  <h3>Ej</h3>
  

# Lee la imagen en escala de grises
img = cv.imread('imagen_oscura.jpg', 0)

# Aplica la transformaci√≥n negativa
img_negativa = 255 - img
  </code></pre>

		  
        <li>3.2.1.2. Transformaciones logar√≠tmicas</li>
		  <p>
    Las transformaciones de intensidad son t√©cnicas clave en el 
    <strong>procesamiento de im√°genes</strong> para mejorar su apariencia. 
    Una de ellas, la <strong>transformaci√≥n logar√≠tmica</strong>, es especialmente √∫til 
    para expandir el rango de valores de p√≠xeles oscuros mientras comprime 
    el de los p√≠xeles m√°s claros.
  </p>

  <p>
    Este tipo de transformaci√≥n es ideal para realzar detalles en las partes oscuras 
    de una imagen, como las sombras, haciendo que los tonos que son dif√≠ciles 
    de distinguir sean m√°s visibles para el ojo humano.
  </p>

  <h3>F√≥rmula matem√°tica</h3>
  <pre>
    s = c ¬∑ log(1 + r)
  </pre>

  <p>
    Donde:
  </p>
  <ul>
    <li><strong>s</strong>: nuevo valor del p√≠xel.</li>
    <li><strong>r</strong>: valor original del p√≠xel.</li>
    <li><strong>c</strong>: constante que ajusta la curva logar√≠tmica para 
        escalar la salida a un rango adecuado.</li>
  </ul>

  <p>
    Un ejemplo claro de aplicaci√≥n se observa en im√°genes con 
    <strong>alto rango din√°mico</strong>, donde una gran variedad de valores 
    de intensidad se comprime en un rango m√°s manejable sin perder 
    detalles en las √°reas oscuras.
  </p>

  <h3>Ej</h3>
 

# Lee la imagen en escala de grises
img = cv.imread('imagen_oscura.jpg', 0)

# Calcula el factor de escala
c = 255 / np.log(1 + np.max(img))

# Aplica la transformaci√≥n logar√≠tmica
img_log = c * np.log1p(np.float32(img))
  </code></pre>
		  
        <li>3.2.1.3. Transformaciones Gamma</li>
      </ul>
		 <p>
    La <strong>transformaci√≥n de potencia</strong> (o <strong>Gamma</strong>) 
    es un tipo de transformaci√≥n de intensidad ideal para 
    <em>ajustar el contraste y la luminosidad</em> de una imagen, 
    especialmente cuando se ve demasiado oscura o demasiado clara.
  </p>

  <h3>Efecto seg√∫n el valor de Gamma</h3>
  <ul>
    <li>
      <strong>Gamma &gt; 1:</strong>  
      La curva de transformaci√≥n es <em>c√≥ncava</em>.  
      Comprime los valores de p√≠xeles claros, haciendo la imagen m√°s oscura.  
      Es √∫til para corregir im√°genes <strong>sobreexpuestas</strong> o muy claras.
    </li>
    <li>
      <strong>Gamma &lt; 1:</strong>  
      La curva de transformaci√≥n es <em>convexa</em>.  
      Expande los valores de p√≠xeles oscuros, haciendo la imagen m√°s clara.  
      Es ideal para realzar detalles en las √°reas oscuras de una imagen.
    </li>
  </ul>

  <h3>Ej</h3>
  

# Lee la imagen en escala de grises
img = cv.imread('imagen_oscura.jpg', 0)

# Convierte la imagen a tipo flotante para la operaci√≥n
img_float = np.float32(img)

# Normaliza los valores de p√≠xeles a un rango de [0, 1]
img_norm = img_float / 255.0

# Aplica la transformaci√≥n Gamma
# Aqu√≠, un gamma de 0.5 har√° la imagen m√°s clara
gamma = 0.5
img_gamma = np.power(img_norm, gamma)

# Convierte de nuevo los valores a un rango de [0, 255] y a tipo uint8
img_gamma = np.uint8(img_gamma * 255)
  </code></pre>

      <h4>3.2.2. Procesamiento de Histogramas</h4>
      <ul>
        <li>3.2.2.1. Ecualizaci√≥n</li>
		    <p>
    El <strong>histograma</strong> de una imagen es una representaci√≥n gr√°fica 
    que muestra la frecuencia de aparici√≥n de cada nivel de intensidad 
    ya sea brillo o gris en la imagen.
  </p>

  <p>
    El <strong>procesamiento de histogramas</strong> busca modificar esta distribuci√≥n 
    para mejorar la calidad visual de la imagen o resaltar detalles.
  </p>

  <h3>Ecualizaci√≥n de Histograma</h3>
  <p>
    La <strong>ecualizaci√≥n de histograma</strong> es una t√©cnica usada para 
    <em>mejorar el contraste</em> de una imagen.  
    Funciona redistribuyendo los niveles de intensidad de manera que 
    el histograma resultante se aproxime a una distribuci√≥n uniforme.
  </p>

  <p>
    Esto hace que las zonas oscuras se aclaren y las zonas claras se 
    oscurezcan un poco, realzando detalles que eran dif√≠ciles de distinguir.
  </p>

  <h3>Ej</h3>

# Lee la imagen en escala de grises
img = cv.imread('imagen_oscura.jpg', 0)

# Aplica la ecualizaci√≥n de histograma
img_eq = cv.equalizeHist(img)

  </code></pre>

  <h3>Resultado</h3>
  <ul>
    <li><strong>Imagen original:</strong> contraste bajo, detalles ocultos.</li>
    <li><strong>Imagen ecualizada:</strong> contraste mejorado, detalles visibles.</li>
  </ul>
        <li>3.2.2.2. Ecualizaci√≥n </li>
		  <p>
    Primero, se calcula el histograma de la imagen, que muestra la frecuencia de cada nivel de intensidad. 
    Las im√°genes con <strong>bajo contraste</strong> suelen tener la mayor√≠a de sus p√≠xeles concentrados 
    en un rango de intensidad limitado.
  </p>

  <h3>2. Mapeo de Intensidades</h3>
  <p>
    La ecualizaci√≥n remapea los valores de intensidad originales a nuevos valores, de forma que la distribuci√≥n 
    de p√≠xeles resultante sea lo m√°s uniforme posible en todo el rango (por ejemplo, de 0 a 255).
  </p>

  <p>
    El resultado es una imagen con <strong>contraste mejorado</strong>, donde los detalles que antes 
    estaban ocultos en √°reas muy oscuras o claras se vuelven m√°s visibles.
  </p>

  <h3>Eje</h3>


# Lee la imagen en escala de grises
img = cv.imread('imagen_oscura.jpg', 0)

# Aplica la ecualizaci√≥n del histograma utilizando la funci√≥n de OpenCV
img_ecualizada = cv.equalizeHist(img)


  </code></pre>
      </ul>
    </section>

    <!-- ABSTRACT -->
    <section id="abstract">
      <h2>4. Abstract (English)</h2>
      <p>[Aqu√≠ escribes en ingl√©s el resumen de 150-200 palabras sobre todo el reporte]</p>
    </section>

    <!-- CONCLUSIONES -->
    <section id="conclusiones">
      <h2>5. Conclusiones Individuales</h2>
      <p><strong>Integrante 1:</strong> [Conclusi√≥n]</p>
      <p><strong>Integrante 2:</strong> [Conclusi√≥n]</p>
      <p><strong>Integrante 3(Carol):</strong>Trabajar en este proyecto me hizo ver lo importante que es 
		  el procesamiento de im√°genes. Todas estas t√©cnicas ayudan a mejorar la visibilidad y a entender mejor 
		  los datos visuales. Aprend√≠mos sobre cosas interesantes como la enorme pontencia que tiene el ojo humano
		  para capturar tantos detalles y como la tecnologia ha avanzado para intentar replicar esto, tambien
		  vimos transformaciones, y otras formulas y maneras para resaltar detalles que antes no se notaban.
		  En general, pudimos observar como cambiar los valores de los p√≠xeles y manipular estos pueden transformar
		  la informaci√≥n que obtenemos¬†de¬†una¬†imagen.</p>
		
    </section>
  </main>

  <footer>
    <p>¬© 2025 Equipo Panteras verdes - Reporte Primer Parcial</p>
  </footer>
</body>
</html>

